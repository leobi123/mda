{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.read_csv('/content/projects_with_region.csv', usecols=['title', 'objective'], encoding='utf-8')\n",
        "texts = df['title'].fillna('') + ' ' + df['objective'].fillna('')\n",
        "all_tokens = []\n",
        "for text in texts:\n",
        "    cleaned = re.sub(r'\\d+', '', text)\n",
        "    cleaned = re.sub(r'[^\\u4e00-\\u9fa5\\w\\s]', '', cleaned)\n",
        "    segments = jieba.lcut(cleaned)\n",
        "    all_tokens.extend([token for token in segments if len(token) > 1])\n",
        "freq = Counter(all_tokens)\n",
        "top200 = [word for word, _ in freq.most_common(200)]\n",
        "with open('stopwords.txt', 'w', encoding='utf-8') as fout:\n",
        "    for word in top200:\n",
        "        fout.write(word + '\\n')\n",
        "print(f\"Generated field-specific stopword list 'stopwords.txt' with {len(top200)} entries.\")\n",
        "print(\"Sample of the first 20 stopwords:\", top200[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVX3_rYGd7-x",
        "outputId": "bbf8a7d0-2449-4fe2-aba0-f98906d5ed30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.622 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.622 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated field-specific stopword list 'stopwords.txt' with 200 entries.\n",
            "Sample of the first 20 stopwords: ['and', 'the', 'of', 'to', 'in', 'will', 'for', 'is', 'with', 'on', 'The', 'by', 'that', 'as', 'be', 'are', 'project', 'from', 'this', 'an']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "import re\n",
        "from collections import Counter\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "INPUT_CSV = '/content/projects_with_region.csv'\n",
        "STOPWORDS_TXT = '/content/stopwords.txt'\n",
        "OUTPUT_CSV = '/content/projects_with_region_preprocessed.csv'\n",
        "N_WORKERS = 4\n",
        "MIN_FREQ = 5\n",
        "\n",
        "print(\"1/5 ▶ Loading CSV …\")\n",
        "df = pd.read_csv(\n",
        "    INPUT_CSV,\n",
        "    usecols=['title', 'objective'],\n",
        "    encoding='utf-8',\n",
        "    engine='python',\n",
        "    on_bad_lines='skip'\n",
        ")\n",
        "texts = (df['title'].fillna('') + ' ' + df['objective'].fillna('')).tolist()\n",
        "\n",
        "print(\"2/5 ▶ Loading stopwords & compiling regex …\")\n",
        "re_num = re.compile(r'\\d+')\n",
        "re_punc = re.compile(r'[^\\u4e00-\\u9fa5\\w\\s]')\n",
        "with open(STOPWORDS_TXT, 'r', encoding='utf-8') as f:\n",
        "    stopwords = set(line.strip() for line in f if line.strip())\n",
        "\n",
        "def init_worker():\n",
        "    import jieba\n",
        "\n",
        "def preprocess(text):\n",
        "    t = re_num.sub('', text)\n",
        "    t = re_punc.sub('', t)\n",
        "    tokens = [w for w in jieba.lcut(t) if len(w) > 1 and w not in stopwords]\n",
        "    return tokens\n",
        "\n",
        "print(f\"3/5 ▶ Tokenizing in parallel ({N_WORKERS} workers) …\")\n",
        "if __name__ == '__main__':\n",
        "    with ProcessPoolExecutor(max_workers=N_WORKERS, initializer=init_worker) as executor:\n",
        "        tokens_list = list(executor.map(preprocess, texts))\n",
        "\n",
        "    df['tokens'] = tokens_list\n",
        "\n",
        "    print(\"4/5 ▶ Filtering low-frequency tokens …\")\n",
        "    all_tokens = [w for seq in tokens_list for w in seq]\n",
        "    freq = Counter(all_tokens)\n",
        "    df['tokens'] = df['tokens'].apply(lambda seq: [w for w in seq if freq[w] >= MIN_FREQ])\n",
        "\n",
        "    print(\"5/5 ▶ Saving results …\")\n",
        "    df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
        "    print(f\"Done! Preprocessed data saved to: {OUTPUT_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3V29OkoeXHg",
        "outputId": "9168e439-2bb0-4f84-bb28-77612db5428e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 ▶ Loading CSV …\n",
            "2/5 ▶ Loading stopwords & compiling regex …\n",
            "3/5 ▶ Tokenizing in parallel (4 workers) …\n",
            "4/5 ▶ Filtering low-frequency tokens …\n",
            "5/5 ▶ Saving results …\n",
            "Done! Preprocessed data saved to: /content/projects_with_region_preprocessed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "df = pd.read_csv(\n",
        "    '/content/projects_with_region_preprocessed.csv',\n",
        "    converters={'tokens': eval},\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "docs = df['tokens'].apply(lambda lst: ' '.join(lst)).tolist()\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=0.9,\n",
        "    min_df=5,\n",
        "    max_features=5000\n",
        ")\n",
        "X = vectorizer.fit_transform(docs)\n",
        "print(f\"Document-term matrix: {X.shape[0]} documents, {X.shape[1]} terms.\")\n",
        "\n",
        "n_topics = 10\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=n_topics,\n",
        "    max_iter=20,\n",
        "    learning_method='batch',\n",
        "    random_state=42\n",
        ")\n",
        "lda.fit(X)\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "topn = 10\n",
        "\n",
        "for idx, comp in enumerate(lda.components_):\n",
        "    top_terms = [terms[i] for i in comp.argsort()[-topn:]][::-1]\n",
        "    print(f\"Topic {idx+1}:\", \" | \".join(top_terms))\n",
        "\n",
        "doc_topic = lda.transform(X)\n",
        "topic_cols = [f\"topic_{i+1}\" for i in range(n_topics)]\n",
        "topic_df = pd.DataFrame(doc_topic, columns=topic_cols)\n",
        "\n",
        "out = pd.concat([df, topic_df], axis=1)\n",
        "out.to_csv('/content/projects_with_region_with_topics.csv', index=False, encoding='utf-8')\n",
        "print(\"Saved preprocessed data with topic distributions to '/content/projects_with_region_with_topics.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X83yLPXYepd8",
        "outputId": "1e4d95ae-219e-47b6-dab6-e4019951f6b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document-term matrix: 15221 documents, 5000 terms.\n",
            "Topic 1: cultural | history | heritage | historical | modern | early | th | were | what | practices\n",
            "Topic 2: optical | devices | light | chemical | chemistry | synthesis | material | molecules | magnetic | organic\n",
            "Topic 3: diseases | drug | therapy | therapeutic | patient | immune | tissue | medical | risk | care\n",
            "Topic 4: theory | computational | algorithms | machine | neural | problems | processing | networks | artificial | cognitive\n",
            "Topic 5: physics | earth | dynamics | water | evolution | space | ocean | formation | modelling | experiments\n",
            "Topic 6: storage | hydrogen | efficiency | performance | battery | heat | safety | cost | solution | integration\n",
            "Topic 7: species | brain | genetic | cellular | proteins | biology | protein | function | functional | changes\n",
            "Topic 8: stakeholders | services | ecosystem | researchers | consortium | projects | countries | research | international | implementation\n",
            "Topic 9: food | waste | products | value | circular | water | soil | manufacturing | co | chain\n",
            "Topic 10: political | people | economic | policies | countries | skills | researchers | gender | education | media\n",
            "Saved preprocessed data with topic distributions to '/content/projects_with_region_with_topics.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "PREPRO_CSV = '/content/projects_with_region_preprocessed.csv'\n",
        "TOPICS_CSV = '/content/projects_with_region_with_topics.csv'\n",
        "N_TOPICS = 10\n",
        "\n",
        "df_tokens = pd.read_csv(PREPRO_CSV, converters={'tokens': eval}, encoding='utf-8')\n",
        "docs = df_tokens['tokens'].apply(lambda lst: ' '.join(lst)).tolist()\n",
        "\n",
        "vectorizer = CountVectorizer(max_df=0.9, min_df=10, max_features=5000)\n",
        "X = vectorizer.fit_transform(docs)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=N_TOPICS, max_iter=20, learning_method='batch', random_state=42)\n",
        "lda.fit(X)\n",
        "\n",
        "print(\"LDA perplexity:\", lda.perplexity(X))\n",
        "\n",
        "doc_topic = lda.transform(X)\n",
        "df_tokens['dominant_topic'] = doc_topic.argmax(axis=1) + 1\n",
        "\n",
        "df_tokens.to_csv(TOPICS_CSV, index=False, encoding='utf-8')\n",
        "print(f\"Saved to: {TOPICS_CSV}\")\n",
        "\n",
        "for t in range(1, N_TOPICS + 1):\n",
        "    subset = df_tokens[df_tokens['dominant_topic'] == t]\n",
        "    sample = subset.sample(5, random_state=42) if len(subset) >= 5 else subset\n",
        "    print(f\"\\n--- Topic {t} sample documents (total {len(subset)}) ---\")\n",
        "    for _, row in sample.iterrows():\n",
        "        title = row.get('title', '')\n",
        "        print(f\"- {title[:50]}...\")\n",
        "\n",
        "topic_counts = df_tokens['dominant_topic'].value_counts().sort_index()\n",
        "print(\"\\nDocument counts by topic:\")\n",
        "print(topic_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYnpws9Lf1Q7",
        "outputId": "879b95b5-c09e-42b3-bd40-1ae9d58f0514"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA perplexity: 2238.6578303807937\n",
            "Saved to: /content/projects_with_region_with_topics.csv\n",
            "\n",
            "--- Topic 1 sample documents (total 2094) ---\n",
            "- Antivirus Pandemic Preparedness EuropeAn pLatform...\n",
            "- Bacteria Intrinsically Orchestrated with Designed ...\n",
            "- The hydrocup: a hollow electrospun scaffold for in...\n",
            "- Mechanisms Linking Early-Life Stress and Resilienc...\n",
            "- Unravelling the mechanisms for recruitment and act...\n",
            "\n",
            "--- Topic 2 sample documents (total 685) ---\n",
            "- New Users for a Better ICOS...\n",
            "- Integration and Digital Demonstration of Low-emiss...\n",
            "- Boosting the exposome space coverage in the aquati...\n",
            "- Aerosols, Convection, Clouds, and Climate Sensitiv...\n",
            "- enhanCed glObaL quantificatiOn and underStanding o...\n",
            "\n",
            "--- Topic 3 sample documents (total 1602) ---\n",
            "- SYstemic Mobilisation for Joint Biodiversity and I...\n",
            "- Advanced multimodal marketplace for low emission a...\n",
            "- SpAce-AIr-Ground Last Mile InfRastructure & Dynami...\n",
            "- Artificial Intelligence for the European Open Scie...\n",
            "- Artificial Intelligence for Traffic Safety between...\n",
            "\n",
            "--- Topic 4 sample documents (total 1560) ---\n",
            "- Development of a Complete Triple Action Injectable...\n",
            "- AIDA: Allergy Immunotherapy based on Designed Alle...\n",
            "- Multi-Omics-based BIomarker Signatures of dietary ...\n",
            "- Total Optical Coherence Characterization for Autom...\n",
            "- Multiscale mechanobiological synergies  in vascula...\n",
            "\n",
            "--- Topic 5 sample documents (total 1568) ---\n",
            "- Model Atmospheres of the Progenitor Stars to Super...\n",
            "- many(Anti)Bodies...\n",
            "- Programmable Active Matter...\n",
            "- Challenges in Competitive Online Optimisation...\n",
            "- Geodesic currents and geometric structures...\n",
            "\n",
            "--- Topic 6 sample documents (total 1992) ---\n",
            "- Soft Enforcement of EU Migration Law...\n",
            "- Venice's Nissology. Reframing the Lagoon City as a...\n",
            "- Towards a strategy to preserve deep-sea biodiversi...\n",
            "- Democratising the Family? Gender Equality, Parenta...\n",
            "- Political Deification: Theorising from Asia...\n",
            "\n",
            "--- Topic 7 sample documents (total 1493) ---\n",
            "- Backscattering coherent Stokes Raman scattering (s...\n",
            "- Energy-efficient Artificial Synapses based on Inno...\n",
            "- Miniaturized sensor system for continuous soil-nut...\n",
            "- Smart, Event-Based Microscopy for Cell Biology...\n",
            "- Continuous sub-mK refrigeration by demagnetization...\n",
            "\n",
            "--- Topic 8 sample documents (total 1926) ---\n",
            "- Sustainable and green electronics for circular eco...\n",
            "- Hybrid nanostructured systems for sustainable ener...\n",
            "- A Disruptively New Approach to Weed Management Sha...\n",
            "- Understanding and designing inorganic materials pr...\n",
            "- Support stakeholders fora on geothermal systems...\n",
            "\n",
            "--- Topic 9 sample documents (total 470) ---\n",
            "- SPin tExturEs and DYnamics in 3D complex nanostruc...\n",
            "- Turku Intersectoral Excellence Scheme...\n",
            "- #NitRecercat: La Nit Europea de la Recerca\"\"...\n",
            "- Acoustic and Thermal Retrofit of Office Building S...\n",
            "- Theory of Fair Machine Learning...\n",
            "\n",
            "--- Topic 10 sample documents (total 1831) ---\n",
            "- STRENGTHENING FARM HEALTH AND SAFETY KNOWLEDGE AND...\n",
            "- Targeting a science-based approach to REd coral re...\n",
            "- Supporting regional environmental sustainability a...\n",
            "- RESILIENCE Preparatory Phase Project...\n",
            "- THE SCIENCE FOR STRONGER SOCIETIES (SCIENCE&FUTURE...\n",
            "\n",
            "Document counts by topic:\n",
            "dominant_topic\n",
            "1     2094\n",
            "2      685\n",
            "3     1602\n",
            "4     1560\n",
            "5     1568\n",
            "6     1992\n",
            "7     1493\n",
            "8     1926\n",
            "9      470\n",
            "10    1831\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "INPUT_PREPROCESSED = '/content/projects_with_region_preprocessed.csv'\n",
        "STOPWORDS_TXT = '/content/stopwords.txt'\n",
        "OUTPUT_TOPICS_CSV = '/content/nmf_document_topics.csv'\n",
        "\n",
        "N_TOPICS = 10\n",
        "MAX_DF = 0.9\n",
        "MIN_DF = 10\n",
        "MAX_FEATURES = 5000\n",
        "\n",
        "df = pd.read_csv(\n",
        "    INPUT_PREPROCESSED,\n",
        "    converters={'tokens': eval},\n",
        "    encoding='utf-8'\n",
        ")\n",
        "docs = df['tokens'].apply(lambda tokens: ' '.join(tokens)).tolist()\n",
        "\n",
        "with open(STOPWORDS_TXT, 'r', encoding='utf-8') as f:\n",
        "    file_stopwords = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "stopwords = list(set(file_stopwords) | set(ENGLISH_STOP_WORDS))\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_df=MAX_DF,\n",
        "    min_df=MIN_DF,\n",
        "    max_features=MAX_FEATURES,\n",
        "    stop_words=stopwords\n",
        ")\n",
        "X = vectorizer.fit_transform(docs)\n",
        "print(f\"Matrix size: {X.shape[0]} documents × {X.shape[1]} features\")\n",
        "\n",
        "nmf = NMF(\n",
        "    n_components=N_TOPICS,\n",
        "    init='nndsvda',\n",
        "    random_state=42,\n",
        "    max_iter=200\n",
        ")\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "for idx, topic_vector in enumerate(H, start=1):\n",
        "    top_indices = topic_vector.argsort()[-10:][::-1]\n",
        "    top_terms = [feature_names[i] for i in top_indices]\n",
        "    print(f\"Topic {idx:>2}:\", \" | \".join(top_terms))\n",
        "\n",
        "topic_columns = [f\"topic_{i}\" for i in range(1, N_TOPICS + 1)]\n",
        "df_topics = pd.DataFrame(W, columns=topic_columns)\n",
        "df_out = pd.concat([df, df_topics], axis=1)\n",
        "df_out.to_csv(OUTPUT_TOPICS_CSV, index=False, encoding='utf-8')\n",
        "print(f\"Document-topic distribution saved to: {OUTPUT_TOPICS_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUf1zvHcgFtp",
        "outputId": "65d1d0a9-dcd9-4527-b942-3349586c7e7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ai', 'eu', 'europe', 'european'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 15221 documents × 5000 features\n",
            "Topic  1: researchers | ri | excellence | international | skills | programme | university | countries | national | stakeholders\n",
            "Topic  2: immune | drug | diseases | therapy | gene | therapeutic | protein | tumor | cellular | proteins\n",
            "Topic  3: hydrogen | storage | battery | waste | heat | renewable | emissions | green | circular | manufacturing\n",
            "Topic  4: physics | optical | theory | light | magnetic | devices | dynamics | matter | theoretical | experimental\n",
            "Topic  5: biodiversity | marine | soil | species | ocean | ecosystems | ecosystem | carbon | conservation | ecological\n",
            "Topic  6: services | security | software | computing | monitoring | intelligence | smart | infrastructure | networks | edge\n",
            "Topic  7: political | cultural | history | heritage | women | historical | gender | practices | language | urban\n",
            "Topic  8: food | waste | products | chain | plant | protein | value | supply | healthy | safety\n",
            "Topic  9: brain | neural | neurons | neuronal | activity | cognitive | memory | stimulation | disorders | imaging\n",
            "Topic 10: water | urban | pollution | wastewater | drinking | membrane | quality | membranes | monitoring | river\n",
            "Document-topic distribution saved to: /content/nmf_document_topics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "INPUT = '/content/nmf_document_topics.csv'\n",
        "OUTPUT = '/content/projects_with_region_final_nmf_classification.csv'\n",
        "\n",
        "TOPIC_LABELS_NMF = {\n",
        "    1: \"Security & Computing Networks\",\n",
        "    2: \"Medical Therapy & Disease\",\n",
        "    3: \"Renewable Energy & Circular Manufacturing\",\n",
        "    4: \"Optical & Theoretical Physics\",\n",
        "    5: \"Marine Ecology & Conservation\",\n",
        "    6: \"International Research Programs\",\n",
        "    7: \"Cultural & Political History\",\n",
        "    8: \"Food Supply & Safety\",\n",
        "    9: \"Neuroscience & Brain Imaging\",\n",
        "    10: \"Water Quality & Urban Pollution\"\n",
        "}\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(INPUT, encoding='utf-8')\n",
        "    topic_cols = [c for c in df.columns if c.startswith('topic_')]\n",
        "    if not topic_cols:\n",
        "        raise ValueError(f\"No topic_ columns found in {INPUT}, columns: {df.columns.tolist()}\")\n",
        "    df['dominant_topic'] = df[topic_cols].idxmax(axis=1).str.replace('topic_', '').astype(int)\n",
        "    df['classification'] = df['dominant_topic'].map(TOPIC_LABELS_NMF)\n",
        "    df.to_csv(OUTPUT, index=False, encoding='utf-8')\n",
        "    print(f\"Saved to: {OUTPUT}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha8fVDuuhtqC",
        "outputId": "e186c463-e146-4132-fbf0-981abdfc4156"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/projects_with_region_final_nmf_classification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "    nmf = pd.read_csv('/content/projects_with_region_final_nmf_classification.csv', encoding='utf-8')\n",
        "    df['text'] = df['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "    df['label'] = nmf['classification']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['text'], df['label'],\n",
        "        test_size=0.2, random_state=42, stratify=df['label']\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=500))\n",
        "    ])\n",
        "\n",
        "    param_dist = {\n",
        "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "        'tfidf__min_df': randint(1, 10),\n",
        "        'tfidf__max_df': uniform(0.6, 0.4),\n",
        "        'clf__C': uniform(0.1, 5.0)\n",
        "    }\n",
        "\n",
        "    rand_search = RandomizedSearchCV(\n",
        "        pipeline,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=15,\n",
        "        cv=2,\n",
        "        n_jobs=1,\n",
        "        scoring='f1_macro',\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    print(rand_search.best_params_)\n",
        "\n",
        "    y_pred = rand_search.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    df['final_class'] = rand_search.predict(df['text'])\n",
        "    df[['text', 'final_class']].to_csv(\n",
        "        '/content/projects_with_region_final_supervised.csv',\n",
        "        index=False, encoding='utf-8'\n",
        "    )\n",
        "    print('Saved to: /content/projects_with_region_final_supervised.csv')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ydVhmQlicnb",
        "outputId": "a514c1f1-87f0-44e9-8bb7-45e77959db5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
            "{'clf__C': np.float64(1.6212112147976887), 'tfidf__max_df': np.float64(0.8099025726528951), 'tfidf__min_df': 9, 'tfidf__ngram_range': (1, 1)}\n",
            "                                           precision    recall  f1-score   support\n",
            "\n",
            "             Cultural & Political History     0.9384    0.9670    0.9525       394\n",
            "                     Food Supply & Safety     0.9136    0.8132    0.8605        91\n",
            "          International Research Programs     0.9330    0.9207    0.9268       454\n",
            "            Marine Ecology & Conservation     0.9198    0.9155    0.9176       213\n",
            "                Medical Therapy & Disease     0.9531    0.9778    0.9653       540\n",
            "             Neuroscience & Brain Imaging     0.9720    0.9085    0.9392       153\n",
            "            Optical & Theoretical Physics     0.9448    0.9520    0.9484       521\n",
            "Renewable Energy & Circular Manufacturing     0.9385    0.9286    0.9335       378\n",
            "            Security & Computing Networks     0.8766    0.9156    0.8957       225\n",
            "          Water Quality & Urban Pollution     0.9403    0.8289    0.8811        76\n",
            "\n",
            "                                 accuracy                         0.9363      3045\n",
            "                                macro avg     0.9330    0.9128    0.9221      3045\n",
            "                             weighted avg     0.9364    0.9363    0.9360      3045\n",
            "\n",
            "Saved to: /content/projects_with_region_final_supervised.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygFOHX_2KwWh",
        "outputId": "3e0e262b-f799-4f2b-df71-91cb24d57d9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "    nmf = pd.read_csv('/content/projects_with_region_final_nmf_classification.csv', encoding='utf-8')\n",
        "    df['text'] = df['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "    df['label'] = nmf['classification']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
        "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "    pipeline = ImbPipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('ros', ros),\n",
        "        ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=500))\n",
        "    ])\n",
        "    param_dist = {\n",
        "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "        'tfidf__min_df': randint(1, 10),\n",
        "        'tfidf__max_df': uniform(0.6, 0.4),\n",
        "        'clf__C': uniform(0.1, 5.0)\n",
        "    }\n",
        "    rand_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=15, cv=2, n_jobs=1, scoring='f1_macro', random_state=42, verbose=1)\n",
        "    rand_search.fit(X_train, y_train)\n",
        "    print(rand_search.best_params_)\n",
        "    y_pred = rand_search.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    df['final_class'] = rand_search.predict(df['text'])\n",
        "    df[['text', 'final_class']].to_csv('/content/projects_with_region_final_supervised_balanced.csv', index=False, encoding='utf-8')\n",
        "    print('/content/projects_with_region_final_supervised_balanced.csv')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sl2SWxGjGe2",
        "outputId": "2dfafe3e-659a-4dee-acd0-ad1a5acd73e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
            "{'clf__C': np.float64(1.6212112147976887), 'tfidf__max_df': np.float64(0.8099025726528951), 'tfidf__min_df': 9, 'tfidf__ngram_range': (1, 1)}\n",
            "                                           precision    recall  f1-score   support\n",
            "\n",
            "             Cultural & Political History     0.9404    0.9619    0.9511       394\n",
            "                     Food Supply & Safety     0.8571    0.8571    0.8571        91\n",
            "          International Research Programs     0.9345    0.9119    0.9231       454\n",
            "            Marine Ecology & Conservation     0.8935    0.9061    0.8998       213\n",
            "                Medical Therapy & Disease     0.9559    0.9630    0.9594       540\n",
            "             Neuroscience & Brain Imaging     0.9286    0.9346    0.9316       153\n",
            "            Optical & Theoretical Physics     0.9511    0.9328    0.9419       521\n",
            "Renewable Energy & Circular Manufacturing     0.9307    0.9233    0.9270       378\n",
            "            Security & Computing Networks     0.8718    0.9067    0.8889       225\n",
            "          Water Quality & Urban Pollution     0.9054    0.8816    0.8933        76\n",
            "\n",
            "                                 accuracy                         0.9304      3045\n",
            "                                macro avg     0.9169    0.9179    0.9173      3045\n",
            "                             weighted avg     0.9306    0.9304    0.9304      3045\n",
            "\n",
            "/content/projects_with_region_final_supervised_balanced.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def main():\n",
        "    df_pre = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "    df_lab = pd.read_csv('/content/projects_with_region_final_supervised_balanced.csv', encoding='utf-8')\n",
        "    df_pre['text'] = df_pre['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "    df_pre['label'] = df_lab['final_class']\n",
        "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "        df_pre['text'], df_pre['label'],\n",
        "        test_size=0.2, random_state=42, stratify=df_pre['label']\n",
        "    )\n",
        "    vectorizer = TfidfVectorizer(max_df=0.81, min_df=9, ngram_range=(1,1))\n",
        "    X_train = vectorizer.fit_transform(X_train_text)\n",
        "    X_test = vectorizer.transform(X_test_text)\n",
        "    clf = LogisticRegression(C=1.6212112147976887, solver='liblinear', class_weight='balanced', max_iter=500, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    X_all = vectorizer.transform(df_pre['text'])\n",
        "    df_pre['fast_final_class'] = clf.predict(X_all)\n",
        "    df_pre[['text', 'fast_final_class']].to_csv('/content/projects_with_region_fast_classification.csv', index=False, encoding='utf-8')\n",
        "    print('/content/projects_with_region_fast_classification.csv')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JXWFVHqj8yl",
        "outputId": "9804081e-0d17-4214-82b5-7e7b858fa98d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           precision    recall  f1-score   support\n",
            "\n",
            "             Cultural & Political History     0.9438    0.9723    0.9578       397\n",
            "                     Food Supply & Safety     0.9213    0.8817    0.9011        93\n",
            "          International Research Programs     0.9291    0.9062    0.9175       448\n",
            "            Marine Ecology & Conservation     0.8964    0.9299    0.9128       214\n",
            "                Medical Therapy & Disease     0.9478    0.9759    0.9617       540\n",
            "             Neuroscience & Brain Imaging     0.9650    0.8961    0.9293       154\n",
            "            Optical & Theoretical Physics     0.9398    0.9380    0.9389       516\n",
            "Renewable Energy & Circular Manufacturing     0.9516    0.9390    0.9453       377\n",
            "            Security & Computing Networks     0.8843    0.9304    0.9068       230\n",
            "          Water Quality & Urban Pollution     0.9833    0.7763    0.8676        76\n",
            "\n",
            "                                 accuracy                         0.9356      3045\n",
            "                                macro avg     0.9362    0.9146    0.9239      3045\n",
            "                             weighted avg     0.9362    0.9356    0.9354      3045\n",
            "\n",
            "/content/projects_with_region_fast_classification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "orig = pd.read_csv(\n",
        "    '/content/projects_with_region.csv',\n",
        "    encoding='utf-8',\n",
        "    engine='python',\n",
        "    on_bad_lines='skip'\n",
        ")\n",
        "\n",
        "clas = pd.read_csv(\n",
        "    '/content/projects_with_region_fast_classification.csv',\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "assert len(orig) == len(clas), f\"Row count mismatch: {len(orig)} vs {len(clas)}\"\n",
        "\n",
        "orig['final_class'] = clas['fast_final_class']\n",
        "\n",
        "out = '/content/projects_with_region_with_classification.csv'\n",
        "orig.to_csv(out, index=False, encoding='utf-8')\n",
        "print(f\"Saved to: {out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91X8Pk2xkbPp",
        "outputId": "69821d68-ee2a-41ff-ef06-d2f3038f9bd1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/projects_with_region_with_classification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def count_terms(docs, term_list):\n",
        "    return np.array([\n",
        "        sum(doc.lower().split().count(t) for t in term_list)\n",
        "        for doc in docs\n",
        "    ]).reshape(-1,1)\n",
        "\n",
        "def main():\n",
        "    df_pre = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "    df_cls = pd.read_csv('/content/projects_with_region_fast_classification.csv', encoding='utf-8')\n",
        "    df_pre['text'] = df_pre['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "    df_pre['label'] = df_cls['fast_final_class']\n",
        "    X = df_pre['text']\n",
        "    y = df_pre['label']\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    water_terms = ['water', 'pollution', 'wastewater', 'membrane', 'river', 'drinking']\n",
        "    marine_terms = ['marine', 'biodiversity', 'ocean', 'ecosystem', 'species', 'soil']\n",
        "    tfidf = TfidfVectorizer(max_df=0.81, min_df=9, ngram_range=(1,1))\n",
        "    Xtr_tfidf = tfidf.fit_transform(X_tr)\n",
        "    Xte_tfidf = tfidf.transform(X_te)\n",
        "    Xtr_water = count_terms(X_tr, water_terms)\n",
        "    Xtr_marine = count_terms(X_tr, marine_terms)\n",
        "    Xte_water = count_terms(X_te, water_terms)\n",
        "    Xte_marine = count_terms(X_te, marine_terms)\n",
        "    Xtr = sparse.hstack([Xtr_tfidf, sparse.csr_matrix(Xtr_water), sparse.csr_matrix(Xtr_marine)])\n",
        "    Xte = sparse.hstack([Xte_tfidf, sparse.csr_matrix(Xte_water), sparse.csr_matrix(Xte_marine)])\n",
        "    clf = LogisticRegression(C=1.62, solver='liblinear', class_weight='balanced', max_iter=500, random_state=42)\n",
        "    clf.fit(Xtr, y_tr)\n",
        "    proba = clf.predict_proba(Xte)\n",
        "    classes = clf.classes_.tolist()\n",
        "    idx_wq = classes.index('Water Quality & Urban Pollution')\n",
        "    idx_me = classes.index('Marine Ecology & Conservation')\n",
        "    y_pred = clf.predict(Xte)\n",
        "    mask = (proba[:, idx_me] > proba.max(axis=1)) & (proba[:, idx_wq] > 0.4)\n",
        "    y_pred[mask] = 'Water Quality & Urban Pollution'\n",
        "    print(\"=== Refined Classification Report ===\")\n",
        "    print(classification_report(y_te, y_pred, digits=4))\n",
        "    cm = confusion_matrix(y_te, y_pred, labels=classes)\n",
        "    print(\"=== Refined Confusion Matrix ===\")\n",
        "    print(pd.DataFrame(cm, index=classes, columns=classes))\n",
        "    Xall_tfidf = tfidf.transform(X)\n",
        "    Xall_water = count_terms(X, water_terms)\n",
        "    Xall_marine = count_terms(X, marine_terms)\n",
        "    Xall = sparse.hstack([Xall_tfidf, sparse.csr_matrix(Xall_water), sparse.csr_matrix(Xall_marine)])\n",
        "    proba_all = clf.predict_proba(Xall)\n",
        "    pred_all = clf.classes_[np.argmax(proba_all, axis=1)]\n",
        "    mask_all = (proba_all[:, idx_me] > np.max(proba_all, axis=1)) & (proba_all[:, idx_wq] > 0.4)\n",
        "    pred_all[mask_all] = 'Water Quality & Urban Pollution'\n",
        "    df_pre['refined_pred'] = pred_all\n",
        "    out = '/content/projects_with_region_refined_classification.csv'\n",
        "    df_pre[['text', 'label', 'refined_pred']].to_csv(out, index=False, encoding='utf-8')\n",
        "    print(f\"Saved to: {out}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0EBhEWfkgY-",
        "outputId": "298e8a59-9bd6-45ed-bd4e-8548fd2f99e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Refined Classification Report ===\n",
            "                                           precision    recall  f1-score   support\n",
            "\n",
            "             Cultural & Political History     0.9518    0.9875    0.9693       400\n",
            "                     Food Supply & Safety     0.9333    0.9032    0.9180        93\n",
            "          International Research Programs     0.9582    0.9323    0.9451       443\n",
            "            Marine Ecology & Conservation     0.8850    0.9302    0.9070       215\n",
            "                Medical Therapy & Disease     0.9566    0.9724    0.9644       544\n",
            "             Neuroscience & Brain Imaging     0.9857    0.9139    0.9485       151\n",
            "            Optical & Theoretical Physics     0.9704    0.9516    0.9609       516\n",
            "Renewable Energy & Circular Manufacturing     0.9571    0.9469    0.9520       377\n",
            "            Security & Computing Networks     0.9507    0.9099    0.9298       233\n",
            "          Water Quality & Urban Pollution     0.8182    0.9863    0.8944        73\n",
            "\n",
            "                                 accuracy                         0.9494      3045\n",
            "                                macro avg     0.9367    0.9434    0.9389      3045\n",
            "                             weighted avg     0.9505    0.9494    0.9495      3045\n",
            "\n",
            "=== Refined Confusion Matrix ===\n",
            "                                           Cultural & Political History  \\\n",
            "Cultural & Political History                                        395   \n",
            "Food Supply & Safety                                                  1   \n",
            "International Research Programs                                       4   \n",
            "Marine Ecology & Conservation                                         3   \n",
            "Medical Therapy & Disease                                             2   \n",
            "Neuroscience & Brain Imaging                                          2   \n",
            "Optical & Theoretical Physics                                         1   \n",
            "Renewable Energy & Circular Manufacturing                             3   \n",
            "Security & Computing Networks                                         4   \n",
            "Water Quality & Urban Pollution                                       0   \n",
            "\n",
            "                                           Food Supply & Safety  \\\n",
            "Cultural & Political History                                  0   \n",
            "Food Supply & Safety                                         84   \n",
            "International Research Programs                               1   \n",
            "Marine Ecology & Conservation                                 2   \n",
            "Medical Therapy & Disease                                     0   \n",
            "Neuroscience & Brain Imaging                                  0   \n",
            "Optical & Theoretical Physics                                 0   \n",
            "Renewable Energy & Circular Manufacturing                     0   \n",
            "Security & Computing Networks                                 3   \n",
            "Water Quality & Urban Pollution                               0   \n",
            "\n",
            "                                           International Research Programs  \\\n",
            "Cultural & Political History                                             0   \n",
            "Food Supply & Safety                                                     1   \n",
            "International Research Programs                                        413   \n",
            "Marine Ecology & Conservation                                            2   \n",
            "Medical Therapy & Disease                                                1   \n",
            "Neuroscience & Brain Imaging                                             1   \n",
            "Optical & Theoretical Physics                                            2   \n",
            "Renewable Energy & Circular Manufacturing                                3   \n",
            "Security & Computing Networks                                            8   \n",
            "Water Quality & Urban Pollution                                          0   \n",
            "\n",
            "                                           Marine Ecology & Conservation  \\\n",
            "Cultural & Political History                                           1   \n",
            "Food Supply & Safety                                                   3   \n",
            "International Research Programs                                        4   \n",
            "Marine Ecology & Conservation                                        200   \n",
            "Medical Therapy & Disease                                              7   \n",
            "Neuroscience & Brain Imaging                                           2   \n",
            "Optical & Theoretical Physics                                          3   \n",
            "Renewable Energy & Circular Manufacturing                              3   \n",
            "Security & Computing Networks                                          3   \n",
            "Water Quality & Urban Pollution                                        0   \n",
            "\n",
            "                                           Medical Therapy & Disease  \\\n",
            "Cultural & Political History                                       0   \n",
            "Food Supply & Safety                                               1   \n",
            "International Research Programs                                    4   \n",
            "Marine Ecology & Conservation                                      3   \n",
            "Medical Therapy & Disease                                        529   \n",
            "Neuroscience & Brain Imaging                                       6   \n",
            "Optical & Theoretical Physics                                      9   \n",
            "Renewable Energy & Circular Manufacturing                          0   \n",
            "Security & Computing Networks                                      1   \n",
            "Water Quality & Urban Pollution                                    0   \n",
            "\n",
            "                                           Neuroscience & Brain Imaging  \\\n",
            "Cultural & Political History                                          1   \n",
            "Food Supply & Safety                                                  0   \n",
            "International Research Programs                                       0   \n",
            "Marine Ecology & Conservation                                         0   \n",
            "Medical Therapy & Disease                                             1   \n",
            "Neuroscience & Brain Imaging                                        138   \n",
            "Optical & Theoretical Physics                                         0   \n",
            "Renewable Energy & Circular Manufacturing                             0   \n",
            "Security & Computing Networks                                         0   \n",
            "Water Quality & Urban Pollution                                       0   \n",
            "\n",
            "                                           Optical & Theoretical Physics  \\\n",
            "Cultural & Political History                                           0   \n",
            "Food Supply & Safety                                                   0   \n",
            "International Research Programs                                        5   \n",
            "Marine Ecology & Conservation                                          0   \n",
            "Medical Therapy & Disease                                              1   \n",
            "Neuroscience & Brain Imaging                                           0   \n",
            "Optical & Theoretical Physics                                        491   \n",
            "Renewable Energy & Circular Manufacturing                              7   \n",
            "Security & Computing Networks                                          1   \n",
            "Water Quality & Urban Pollution                                        1   \n",
            "\n",
            "                                           Renewable Energy & Circular Manufacturing  \\\n",
            "Cultural & Political History                                                       0   \n",
            "Food Supply & Safety                                                               2   \n",
            "International Research Programs                                                    7   \n",
            "Marine Ecology & Conservation                                                      1   \n",
            "Medical Therapy & Disease                                                          1   \n",
            "Neuroscience & Brain Imaging                                                       0   \n",
            "Optical & Theoretical Physics                                                      5   \n",
            "Renewable Energy & Circular Manufacturing                                        357   \n",
            "Security & Computing Networks                                                      0   \n",
            "Water Quality & Urban Pollution                                                    0   \n",
            "\n",
            "                                           Security & Computing Networks  \\\n",
            "Cultural & Political History                                           2   \n",
            "Food Supply & Safety                                                   0   \n",
            "International Research Programs                                        3   \n",
            "Marine Ecology & Conservation                                          2   \n",
            "Medical Therapy & Disease                                              0   \n",
            "Neuroscience & Brain Imaging                                           1   \n",
            "Optical & Theoretical Physics                                          1   \n",
            "Renewable Energy & Circular Manufacturing                              2   \n",
            "Security & Computing Networks                                        212   \n",
            "Water Quality & Urban Pollution                                        0   \n",
            "\n",
            "                                           Water Quality & Urban Pollution  \n",
            "Cultural & Political History                                             1  \n",
            "Food Supply & Safety                                                     1  \n",
            "International Research Programs                                          2  \n",
            "Marine Ecology & Conservation                                            2  \n",
            "Medical Therapy & Disease                                                2  \n",
            "Neuroscience & Brain Imaging                                             1  \n",
            "Optical & Theoretical Physics                                            4  \n",
            "Renewable Energy & Circular Manufacturing                                2  \n",
            "Security & Computing Networks                                            1  \n",
            "Water Quality & Urban Pollution                                         72  \n",
            "Saved to: /content/projects_with_region_refined_classification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "df_pre = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "df_pre['text'] = df_pre['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "df_cls = pd.read_csv('/content/projects_with_region_fast_classification.csv', encoding='utf-8')\n",
        "df_pre['label'] = df_cls['fast_final_class']\n",
        "\n",
        "X = df_pre['text']\n",
        "y = df_pre['label']\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.81, min_df=9, ngram_range=(1,1))\n",
        "Xtr = tfidf.fit_transform(X_tr)\n",
        "Xte = tfidf.transform(X_te)\n",
        "\n",
        "clf = LogisticRegression(C=1.62, solver='liblinear', class_weight='balanced', max_iter=500, random_state=42)\n",
        "clf.fit(Xtr, y_tr)\n",
        "\n",
        "proba = clf.predict_proba(Xte)\n",
        "classes = clf.classes_.tolist()\n",
        "i_wq = classes.index('Water Quality & Urban Pollution')\n",
        "i_me = classes.index('Marine Ecology & Conservation')\n",
        "\n",
        "best_t = 0\n",
        "best_f1 = 0\n",
        "for t in np.linspace(0.1, 0.9, 81):\n",
        "    preds = clf.predict(Xte)\n",
        "    mask = (proba[:, i_me] >= proba.max(axis=1)) & (proba[:, i_wq] > t)\n",
        "    preds[mask] = 'Water Quality & Urban Pollution'\n",
        "    f1 = f1_score(y_te, preds, labels=['Water Quality & Urban Pollution'], average='macro')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_t = t\n",
        "\n",
        "print(f\"Best threshold: {best_t:.2f}, tuned WQ F1: {best_f1:.4f}\")\n",
        "\n",
        "X_all = tfidf.transform(df_pre['text'])\n",
        "proba_all = clf.predict_proba(X_all)\n",
        "pred_all = clf.classes_[np.argmax(proba_all, axis=1)]\n",
        "mask_all = (proba_all[:, i_me] >= np.max(proba_all, axis=1)) & (proba_all[:, i_wq] > best_t)\n",
        "pred_all[mask_all] = 'Water Quality & Urban Pollution'\n",
        "\n",
        "df_pre['refined_pred'] = pred_all\n",
        "out = '/content/projects_with_region_refined_threshold_classification.csv'\n",
        "df_pre.to_csv(out, index=False, encoding='utf-8')\n",
        "print(f\"Refined results saved to: {out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXrITlEfk1Q-",
        "outputId": "1f36d727-bcae-49a9-88cd-e41406470447"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.36, tuned WQ F1: 0.9362\n",
            "Refined results saved to: /content/projects_with_region_refined_threshold_classification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "df_pre = pd.read_csv('/content/projects_with_region_preprocessed.csv', converters={'tokens': eval}, encoding='utf-8')\n",
        "df_pre['text'] = df_pre['tokens'].apply(lambda lst: ' '.join(lst))\n",
        "df_cls = pd.read_csv('/content/projects_with_region_fast_classification.csv', encoding='utf-8')\n",
        "df_pre['label'] = df_cls['fast_final_class']\n",
        "\n",
        "X = df_pre['text']\n",
        "y = df_pre['label']\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.81, min_df=9, ngram_range=(1,2), strip_accents='unicode')\n",
        "Xtr = tfidf.fit_transform(X_tr)\n",
        "Xte = tfidf.transform(X_te)\n",
        "\n",
        "clf = LogisticRegression(C=1.62, solver='liblinear', class_weight='balanced', max_iter=500, random_state=42)\n",
        "clf.fit(Xtr, y_tr)\n",
        "\n",
        "proba = clf.predict_proba(Xte)\n",
        "classes = clf.classes_.tolist()\n",
        "i_wq = classes.index('Water Quality & Urban Pollution')\n",
        "i_me = classes.index('Marine Ecology & Conservation')\n",
        "\n",
        "best_t, best_f1 = 0, 0\n",
        "for t in np.linspace(0.1, 0.9, 81):\n",
        "    preds = clf.predict(Xte)\n",
        "    mask = (proba[:, i_me] >= proba.max(axis=1)) & (proba[:, i_wq] > t)\n",
        "    preds[mask] = 'Water Quality & Urban Pollution'\n",
        "    f1 = f1_score(y_te, preds, labels=['Water Quality & Urban Pollution'], average='macro')\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_t = f1, t\n",
        "\n",
        "print(f\"[Bi-gram] Best threshold = {best_t:.2f}, WQ F1 = {best_f1:.4f}\")\n",
        "\n",
        "preds = clf.predict(Xte)\n",
        "mask = (proba[:, i_me] >= proba.max(axis=1)) & (proba[:, i_wq] > best_t)\n",
        "preds[mask] = 'Water Quality & Urban Pollution'\n",
        "print(classification_report(y_te, preds, digits=4))\n",
        "\n",
        "X_all = tfidf.transform(df_pre['text'])\n",
        "proba_all = clf.predict_proba(X_all)\n",
        "pred_all = clf.classes_[np.argmax(proba_all, axis=1)]\n",
        "mask_all = (proba_all[:, i_me] >= np.max(proba_all, axis=1)) & (proba_all[:, i_wq] > best_t)\n",
        "pred_all[mask_all] = 'Water Quality & Urban Pollution'\n",
        "\n",
        "df_pre['refined_ngram_pred'] = pred_all\n",
        "out = '/content/projects_with_region_refined_ngram_threshold.csv'\n",
        "df_pre.to_csv(out, index=False, encoding='utf-8')\n",
        "print(f\"Saved to: {out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6DxoTxDlHP_",
        "outputId": "ef49dd21-1293-4338-9104-818729fdd170"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Bi-gram] Best threshold = 0.35, WQ F1 = 0.9437\n",
            "                                           precision    recall  f1-score   support\n",
            "\n",
            "             Cultural & Political History     0.9542    0.9900    0.9718       400\n",
            "                     Food Supply & Safety     0.9341    0.9140    0.9239        93\n",
            "          International Research Programs     0.9513    0.9255    0.9382       443\n",
            "            Marine Ecology & Conservation     0.9058    0.9395    0.9224       215\n",
            "                Medical Therapy & Disease     0.9534    0.9779    0.9655       544\n",
            "             Neuroscience & Brain Imaging     0.9714    0.9007    0.9347       151\n",
            "            Optical & Theoretical Physics     0.9687    0.9593    0.9640       516\n",
            "Renewable Energy & Circular Manufacturing     0.9450    0.9576    0.9513       377\n",
            "            Security & Computing Networks     0.9556    0.9227    0.9389       233\n",
            "          Water Quality & Urban Pollution     0.9710    0.9178    0.9437        73\n",
            "\n",
            "                                 accuracy                         0.9521      3045\n",
            "                                macro avg     0.9511    0.9405    0.9454      3045\n",
            "                             weighted avg     0.9523    0.9521    0.9519      3045\n",
            "\n",
            "Saved to: /content/projects_with_region_refined_ngram_threshold.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "\n",
        "orig = pd.read_csv('/content/projects_with_region.csv', encoding='utf-8', engine='python', on_bad_lines='skip')\n",
        "ref = pd.read_csv('/content/projects_with_region_refined_ngram_threshold.csv', encoding='utf-8')\n",
        "\n",
        "assert len(orig) == len(ref), f\"Row count mismatch: {len(orig)} vs {len(ref)}\"\n",
        "\n",
        "topic_cols = [c for c in ref.columns if c.startswith('refined')]\n",
        "if not topic_cols:\n",
        "    raise KeyError(\"No column starting with 'refined' found in classification results\")\n",
        "topic_col = topic_cols[0]\n",
        "\n",
        "orig['topic'] = ref[topic_col]\n",
        "\n",
        "out_path = '/content/projects_with_region_with_topic.csv'\n",
        "orig.to_csv(out_path, index=False, encoding='utf-8')\n",
        "print(f\"Saved to: {out_path} (added topic from {topic_col})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx5z8U30lRV0",
        "outputId": "01296ead-00fa-4fba-878c-0bddcf26cf15"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/projects_with_region_with_topic.csv (added topic from refined_ngram_pred)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/projects_with_region_with_topic.csv', encoding='utf-8')\n",
        "df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
        "df.to_csv('/content/projects_with_region_with_topic.csv', index=False, encoding='utf-8')\n",
        "print('/content/projects_with_region_with_topic.csv')\n"
      ],
      "metadata": {
        "id": "kmsc_s_AgpOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0641df-7cb0-4329-cab8-1d4931f68dc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/projects_with_region_with_topic.csv\n"
          ]
        }
      ]
    }
  ]
}